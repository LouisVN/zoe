{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Zoe : The Kafka companion Zoe is a command line tool to interact with kafka in an easy and intuitive way. Wanna see this in action ? check out this demo... Zoe really shines when it comes to interacting with cloud hosted kafka clusters (kubernetes, AWS, etc.) due to its ability to offload consumption and execution to kubernetes pods or lambda functions (more runners will be supported in the future). Status Zoe has been open sourced very recently and is not GA yet. It is actively being improved towards stabilization. Documentation is also in progress. That said, we are already using it at Adevinta and you can already start trying it if you are not afraid of digging into the code to solve some eventual undocumented problems :) . Key features Here are some of the most interesting features of zoe : Consume kafka topics from a specific point in time (ex. using --from 'PT5h from the last 5 hours). Filter data based on content (ex. using --filter \"id == '12345'\" filters records with the selected id). Supports offloading consumption of data to multiple lambda functions, kubernetes pods, etc. for parallelism (ex. adding -x kubernetes would offload all the requests to a configured kubernetes cluster). Monitor consumer groups' offsets. Upload avro schemas from a .avsc or .avdl file using different naming strategies. ... and more. Go to the install section for instructions on how to install the zoe CLI.","title":"Zoe : The Kafka companion"},{"location":"#zoe-the-kafka-companion","text":"Zoe is a command line tool to interact with kafka in an easy and intuitive way. Wanna see this in action ? check out this demo... Zoe really shines when it comes to interacting with cloud hosted kafka clusters (kubernetes, AWS, etc.) due to its ability to offload consumption and execution to kubernetes pods or lambda functions (more runners will be supported in the future).","title":"Zoe : The Kafka companion"},{"location":"#status","text":"Zoe has been open sourced very recently and is not GA yet. It is actively being improved towards stabilization. Documentation is also in progress. That said, we are already using it at Adevinta and you can already start trying it if you are not afraid of digging into the code to solve some eventual undocumented problems :) .","title":"Status"},{"location":"#key-features","text":"Here are some of the most interesting features of zoe : Consume kafka topics from a specific point in time (ex. using --from 'PT5h from the last 5 hours). Filter data based on content (ex. using --filter \"id == '12345'\" filters records with the selected id). Supports offloading consumption of data to multiple lambda functions, kubernetes pods, etc. for parallelism (ex. adding -x kubernetes would offload all the requests to a configured kubernetes cluster). Monitor consumer groups' offsets. Upload avro schemas from a .avsc or .avdl file using different naming strategies. ... and more. Go to the install section for instructions on how to install the zoe CLI.","title":"Key features"},{"location":"install/","text":"Install Zoe CLI Platform package install (Experimental - does not require an already installed JDK) You can install zoe using one of the platform packages listed below. Only few platforms are supported for now but more will come in the future. The platform packages are self contained. They ship with their own version of the java virtual machine (thus the higher size of the package). The host machine does not need to have it's own java runtime. The platform packages are built with jpackage and JDK 14. Ubuntu / Debian Download the .deb package of the zoe CLI from the latest release page and install it using dpkg : ZOE_VERSION=0.3.0 # change it to the suitable version curl -L \"https://github.com/adevinta/zoe/releases/download/v${ZOE_VERSION}/zoe_${ZOE_VERSION}-1_amd64.deb\" -o /tmp/zoe.deb sudo dpkg -i /tmp/zoe.deb Add the /opt/zoe/bin into your path by appending the following line in your .bashrc (or .zshrc ) : PATH=$PATH:/opt/zoe/bin Init zoe configuration : zoe config init You are now ready to use zoe. Go to the ./tutorials folder to start learning zoe. Centos Download the .rpm package of the zoe CLI from the latest release page and install it using dpkg : ZOE_VERSION=0.3.0 # change it to the suitable version sudo rpm -i \"https://github.com/adevinta/zoe/releases/download/v${ZOE_VERSION}/zoe-${ZOE_VERSION}-1.x86_64.rpm\" Add the /opt/zoe/bin into your path by appending the following line in your .bashrc (or .zshrc ) : PATH=$PATH:/opt/zoe/bin Init zoe configuration : zoe config init You are now ready to use zoe. Go to the ./tutorials folder to start learning zoe. Manual tarball install (requires a JDK on the host machine) Java 11 or higher is required in order to install the runtime-less tarball packages. They only ship with the Zoe CLI jar. If you don't have java installed already, you can use sdkman for an easy install and version management of the JDK. If you don't want to install java you can try one of the platform packages provided above. Once java is installed, proceed with the following steps : Download the runtime-less zip or tar package of the zoe CLI from the latest release page and uncompress it into your home directory (or wherever you wish) ZOE_VERSION=0.3.0 # change it to the suitable version curl -L \"https://github.com/adevinta/zoe/releases/download/v${ZOE_VERSION}/zoe-${ZOE_VERSION}.tar.gz\" | tar -zx -C $HOME Add the $HOME/zoe/bin into your path by appending the following line in your .bashrc (or .zshrc ) : PATH=$PATH:$HOME/zoe/bin Init zoe configuration : zoe config init You are now ready to use zoe. Go to the ./tutorials folder to start learning zoe.","title":"Install"},{"location":"install/#install-zoe-cli","text":"","title":"Install Zoe CLI"},{"location":"install/#platform-package-install-experimental-does-not-require-an-already-installed-jdk","text":"You can install zoe using one of the platform packages listed below. Only few platforms are supported for now but more will come in the future. The platform packages are self contained. They ship with their own version of the java virtual machine (thus the higher size of the package). The host machine does not need to have it's own java runtime. The platform packages are built with jpackage and JDK 14.","title":"Platform package install (Experimental - does not require an already installed JDK)"},{"location":"install/#ubuntu-debian","text":"Download the .deb package of the zoe CLI from the latest release page and install it using dpkg : ZOE_VERSION=0.3.0 # change it to the suitable version curl -L \"https://github.com/adevinta/zoe/releases/download/v${ZOE_VERSION}/zoe_${ZOE_VERSION}-1_amd64.deb\" -o /tmp/zoe.deb sudo dpkg -i /tmp/zoe.deb Add the /opt/zoe/bin into your path by appending the following line in your .bashrc (or .zshrc ) : PATH=$PATH:/opt/zoe/bin Init zoe configuration : zoe config init You are now ready to use zoe. Go to the ./tutorials folder to start learning zoe.","title":"Ubuntu / Debian"},{"location":"install/#centos","text":"Download the .rpm package of the zoe CLI from the latest release page and install it using dpkg : ZOE_VERSION=0.3.0 # change it to the suitable version sudo rpm -i \"https://github.com/adevinta/zoe/releases/download/v${ZOE_VERSION}/zoe-${ZOE_VERSION}-1.x86_64.rpm\" Add the /opt/zoe/bin into your path by appending the following line in your .bashrc (or .zshrc ) : PATH=$PATH:/opt/zoe/bin Init zoe configuration : zoe config init You are now ready to use zoe. Go to the ./tutorials folder to start learning zoe.","title":"Centos"},{"location":"install/#manual-tarball-install-requires-a-jdk-on-the-host-machine","text":"Java 11 or higher is required in order to install the runtime-less tarball packages. They only ship with the Zoe CLI jar. If you don't have java installed already, you can use sdkman for an easy install and version management of the JDK. If you don't want to install java you can try one of the platform packages provided above. Once java is installed, proceed with the following steps : Download the runtime-less zip or tar package of the zoe CLI from the latest release page and uncompress it into your home directory (or wherever you wish) ZOE_VERSION=0.3.0 # change it to the suitable version curl -L \"https://github.com/adevinta/zoe/releases/download/v${ZOE_VERSION}/zoe-${ZOE_VERSION}.tar.gz\" | tar -zx -C $HOME Add the $HOME/zoe/bin into your path by appending the following line in your .bashrc (or .zshrc ) : PATH=$PATH:$HOME/zoe/bin Init zoe configuration : zoe config init You are now ready to use zoe. Go to the ./tutorials folder to start learning zoe.","title":"Manual tarball install (requires a JDK on the host machine)"},{"location":"tutorials/avro/","text":"Zoe with Avro This tutorial shows zoe support for avro and the schema registry. If you are new to zoe, start with the simple example . What you will learn In this tutorial, you will learn the following aspects of zoe : listing avro schemas registerd in the schema registry deploying .avdl avro schemas writing json data into kafka topics using avro reading avro data from a topic using jmespath expressions to filter read data based on its content. Prerequisites For this tutorial you will need : Zoe Docker and docker-compose Prepare the environment Clone the repository : git clone https://github.com/adevinta/zoe.git Go to the directory : tutorials/simple Spin up the kafka cluster : docker-compose up -d . Point zoe to this tutorial's config : export ZOE_CONFIG_DIR=$(pwd)/config Now, you're ready to use zoe to interact with the local kafka cluster. This cluster is available in the provided config above under the local alias (take a look at zoe-config/default.yml ) Start using Zoe In this tutorial we are still using the cats facts data that we used in the previous tutorial. But this time we are serializing into kafka in avro format. In order to do this, we have provided a ready to use avro schema that describe the fact cats data in the schema.avdl file. The first step is to deploy this schema. Usually, to deploy an .avdl file into the schema registry we first need to compile it into an .avsc file before posting it to the registry. With zoe, this compilation step is done automatically for us. In fact, zoe handles .avdl files seamlessly. # list currently registered avro schemas zoe -q -c local schemas list # deploy the cat facts schema from the zoe -q -c local schemas deploy \\ --avdl \\ --from-file schema.avdl \\ --name CatFact \\ --strategy topicRecord \\ --topic input \\ --dry-run Produce some events from the data.json using avro : zoe -c local topics produce --topic input --from-file $(pwd)/data.json Read the data from the topic : # read the 10 last events zoe -q -o table -c local topics consume input -n 10 --from 'PT1h' # display events in a table zoe -q -o table -c local topics consume input -n 10 --from 'PT1h' \\ --query '{id: _id, type: type, user: user, upvotes: upvotes}' # filter out Kasimir's data zoe -q -o table -c local topics consume input -n 10 --from 'PT1h' \\ --query '{id: _id, type: type, user: user, upvotes: upvotes}' \\ --filter \"user.name.first == 'Kasimir'\"","title":"Zoe with Avro"},{"location":"tutorials/avro/#zoe-with-avro","text":"This tutorial shows zoe support for avro and the schema registry. If you are new to zoe, start with the simple example .","title":"Zoe with Avro"},{"location":"tutorials/avro/#what-you-will-learn","text":"In this tutorial, you will learn the following aspects of zoe : listing avro schemas registerd in the schema registry deploying .avdl avro schemas writing json data into kafka topics using avro reading avro data from a topic using jmespath expressions to filter read data based on its content.","title":"What you will learn"},{"location":"tutorials/avro/#prerequisites","text":"For this tutorial you will need : Zoe Docker and docker-compose","title":"Prerequisites"},{"location":"tutorials/avro/#prepare-the-environment","text":"Clone the repository : git clone https://github.com/adevinta/zoe.git Go to the directory : tutorials/simple Spin up the kafka cluster : docker-compose up -d . Point zoe to this tutorial's config : export ZOE_CONFIG_DIR=$(pwd)/config Now, you're ready to use zoe to interact with the local kafka cluster. This cluster is available in the provided config above under the local alias (take a look at zoe-config/default.yml )","title":"Prepare the environment"},{"location":"tutorials/avro/#start-using-zoe","text":"In this tutorial we are still using the cats facts data that we used in the previous tutorial. But this time we are serializing into kafka in avro format. In order to do this, we have provided a ready to use avro schema that describe the fact cats data in the schema.avdl file. The first step is to deploy this schema. Usually, to deploy an .avdl file into the schema registry we first need to compile it into an .avsc file before posting it to the registry. With zoe, this compilation step is done automatically for us. In fact, zoe handles .avdl files seamlessly. # list currently registered avro schemas zoe -q -c local schemas list # deploy the cat facts schema from the zoe -q -c local schemas deploy \\ --avdl \\ --from-file schema.avdl \\ --name CatFact \\ --strategy topicRecord \\ --topic input \\ --dry-run Produce some events from the data.json using avro : zoe -c local topics produce --topic input --from-file $(pwd)/data.json Read the data from the topic : # read the 10 last events zoe -q -o table -c local topics consume input -n 10 --from 'PT1h' # display events in a table zoe -q -o table -c local topics consume input -n 10 --from 'PT1h' \\ --query '{id: _id, type: type, user: user, upvotes: upvotes}' # filter out Kasimir's data zoe -q -o table -c local topics consume input -n 10 --from 'PT1h' \\ --query '{id: _id, type: type, user: user, upvotes: upvotes}' \\ --filter \"user.name.first == 'Kasimir'\"","title":"Start using Zoe"},{"location":"tutorials/simple/","text":"A simple example This tutorial walks you through the most basic functionalities of zoe. It makes use of a dataset downloaded from the Cat Facts API to explore reading and writing data from / into kafka using zoe. In this tutorial, we will spin up a simple one node kafka cluster and then interact with it using zoe. If you want to run this tutorial yourself, you can find all the relevant files / datasets here . What you will learn In this tutorial, you will learn the following aspects of zoe : listing topics describing topics writing json data into kafka topics reading json data from a topic using jmespath expressions to filter read data based on its content. Prerequisites For this tutorial you will need : Zoe (follow instructions here ) Docker and docker-compose Prepare the environment Clone the repository : git clone https://github.com/adevinta/zoe.git Go to the directory : tutorials/simple Spin up the kafka cluster : docker-compose up -d . Point zoe to this tutorial's config : export ZOE_CONFIG_DIR=$(pwd)/config Now, you're ready to use zoe to interact with the local kafka cluster. This cluster is available in the provided config above under the local alias (take a look at zoe-config/default.yml ) Start using Zoe To list and describe topics : # interact with the topics zoe -c local topics list zoe -c local topics describe input-events-topic To avoid repeating the -c local option on each command you can set the local cluster as the default one for the current session : export ZOE_CLUSTER=local We have some cats facts in the data.json file. Let's put it into the input-events-topic aliased as the input in zoe's configuration ( zoe-config/default.yml ) : zoe topics produce --topic input --from-file $(pwd)/data.json Read the data that we have just inserted : # read the 10 last events zoe -q -o table topics consume input -n 10 --from 'PT1h' # display events in a table zoe -q -o table topics consume input -n 10 --from 'PT1h' \\ --query '{id: _id, type: type, user: user, upvotes: upvotes}' # filter out Kasimir's data zoe -q -o table topics consume input -n 10 --from 'PT1h' \\ --query '{id: _id, type: type, user: user, upvotes: upvotes}' \\ --filter \"user.name.first == 'Kasimir'\"","title":"A simple example"},{"location":"tutorials/simple/#a-simple-example","text":"This tutorial walks you through the most basic functionalities of zoe. It makes use of a dataset downloaded from the Cat Facts API to explore reading and writing data from / into kafka using zoe. In this tutorial, we will spin up a simple one node kafka cluster and then interact with it using zoe. If you want to run this tutorial yourself, you can find all the relevant files / datasets here .","title":"A simple example"},{"location":"tutorials/simple/#what-you-will-learn","text":"In this tutorial, you will learn the following aspects of zoe : listing topics describing topics writing json data into kafka topics reading json data from a topic using jmespath expressions to filter read data based on its content.","title":"What you will learn"},{"location":"tutorials/simple/#prerequisites","text":"For this tutorial you will need : Zoe (follow instructions here ) Docker and docker-compose","title":"Prerequisites"},{"location":"tutorials/simple/#prepare-the-environment","text":"Clone the repository : git clone https://github.com/adevinta/zoe.git Go to the directory : tutorials/simple Spin up the kafka cluster : docker-compose up -d . Point zoe to this tutorial's config : export ZOE_CONFIG_DIR=$(pwd)/config Now, you're ready to use zoe to interact with the local kafka cluster. This cluster is available in the provided config above under the local alias (take a look at zoe-config/default.yml )","title":"Prepare the environment"},{"location":"tutorials/simple/#start-using-zoe","text":"To list and describe topics : # interact with the topics zoe -c local topics list zoe -c local topics describe input-events-topic To avoid repeating the -c local option on each command you can set the local cluster as the default one for the current session : export ZOE_CLUSTER=local We have some cats facts in the data.json file. Let's put it into the input-events-topic aliased as the input in zoe's configuration ( zoe-config/default.yml ) : zoe topics produce --topic input --from-file $(pwd)/data.json Read the data that we have just inserted : # read the 10 last events zoe -q -o table topics consume input -n 10 --from 'PT1h' # display events in a table zoe -q -o table topics consume input -n 10 --from 'PT1h' \\ --query '{id: _id, type: type, user: user, upvotes: upvotes}' # filter out Kasimir's data zoe -q -o table topics consume input -n 10 --from 'PT1h' \\ --query '{id: _id, type: type, user: user, upvotes: upvotes}' \\ --filter \"user.name.first == 'Kasimir'\"","title":"Start using Zoe"}]}